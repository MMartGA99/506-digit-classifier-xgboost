{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0049bd72",
   "metadata": {},
   "source": [
    "* https://stackoverflow.com/questions/42471523/how-can-i-generate-a-proper-mnist-image\n",
    "* https://stackoverflow.com/questions/45539289/convert-image-from-28-28-4-to-2d-flat-array-and-write-to-csv\n",
    "* https://stackoverflow.com/questions/61552402/if-image-has-28-28-3-shape-how-do-i-convert-it-to-28-28-1\n",
    "* https://stackoverflow.com/questions/51205502/convert-a-black-and-white-image-to-array-of-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aab723e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/champions2019/opt/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB\n",
      "    ca-certificates-2022.4.26  |       hecd8cb5_0         124 KB\n",
      "    certifi-2022.5.18.1        |   py39hecd8cb5_0         148 KB\n",
      "    libxgboost-1.5.0           |       he9d5cce_1         1.2 MB\n",
      "    openssl-1.1.1o             |       hca72f7f_0         2.2 MB\n",
      "    py-xgboost-1.5.0           |   py39hecd8cb5_1         166 KB\n",
      "    xgboost-1.5.0              |   py39hecd8cb5_1          25 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  pkgs/main/osx-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  libxgboost         pkgs/main/osx-64::libxgboost-1.5.0-he9d5cce_1\n",
      "  py-xgboost         pkgs/main/osx-64::py-xgboost-1.5.0-py39hecd8cb5_1\n",
      "  xgboost            pkgs/main/osx-64::xgboost-1.5.0-py39hecd8cb5_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2022.3.29-hecd8cb5_0 --> 2022.4.26-hecd8cb5_0\n",
      "  certifi                          2021.10.8-py39hecd8cb5_2 --> 2022.5.18.1-py39hecd8cb5_0\n",
      "  openssl                                 1.1.1n-hca72f7f_0 --> 1.1.1o-hca72f7f_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "xgboost-1.5.0        | 25 KB     | ##################################### | 100% \n",
      "libxgboost-1.5.0     | 1.2 MB    | ##################################### | 100% \n",
      "py-xgboost-1.5.0     | 166 KB    | ##################################### | 100% \n",
      "certifi-2022.5.18.1  | 148 KB    | ##################################### | 100% \n",
      "ca-certificates-2022 | 124 KB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 2.2 MB    | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "! conda install xgboost -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0470e27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/champions2019/opt/anaconda3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d86048f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the mnist datsaet\n",
    "\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb79c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a063aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                       test_size=0.2, \n",
    "                                       random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6a2f1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09061db",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "319596ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, min_samples_leaf=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeling: random forest (arbitrary hyperparameters)\n",
    "rf = RandomForestClassifier(max_depth=8, min_samples_leaf=10, n_estimators=100)\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffb3a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '4', '8', '7', '7', '0', '6', '2', '7', '9']\n",
      "['8', '4', '8', '7', '7', '0', '6', '2', '7', '4']\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_preds=rf.predict(X_test_scaled)\n",
    "print(list(y_preds[:10]))\n",
    "print(list(y_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee8609d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246428571428571\n",
      "0.9252220868700481\n",
      "0.9237204888477797\n",
      "0.9242368733924676\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "print(metrics.accuracy_score(y_test, y_preds))\n",
    "print(metrics.precision_score(y_test, y_preds,average='macro'))\n",
    "print(metrics.recall_score(y_test, y_preds,average='macro'))\n",
    "print(metrics.f1_score(y_test, y_preds,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9e295",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d91589d",
   "metadata": {},
   "source": [
    "There are in general two ways that you can control overfitting in XGBoost:\n",
    "\n",
    "- The first way is to directly control model complexity.\n",
    "\n",
    "    - This includes max_depth, min_child_weight and gamma.\n",
    "\n",
    "- The second way is to add randomness to make training robust to noise.\n",
    "\n",
    "    - This includes subsample and colsample_bytree.\n",
    "\n",
    "    - You can also reduce stepsize eta. Remember to increase num_round when you do so.\n",
    "\n",
    "[source](https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html#:~:text=There%20are%20in,you%20do%20so.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:48:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# modeling: random forest (arbitrary hyperparameters)\n",
    "rf = XGBClassifier(max_depth=6, min_child_weight=1, gamma=0, subsample=1, learning_rate=0.3)\n",
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6f8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
